{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('nlp_start/train.csv')\n",
    "test_df=pd.read_csv('nlp_start/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>107</td>\n",
       "      <td>accident</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>I-77 Mile Marker 31 South Mooresville  Iredell...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>7687</td>\n",
       "      <td>panic</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>tomorrow's going to be a year since I went to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4259</th>\n",
       "      <td>6051</td>\n",
       "      <td>heat%20wave</td>\n",
       "      <td>Arnhem, the Netherlands</td>\n",
       "      <td>Arnhem Weather - &amp;lt;p&amp;gt;An unrelenting and d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>3045</td>\n",
       "      <td>death</td>\n",
       "      <td>Home of the Takers.</td>\n",
       "      <td>Y'all PUSSSSSSSSSY AND SHOOOK TO DEATH OF ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>8684</td>\n",
       "      <td>sinkhole</td>\n",
       "      <td>Haddonfield, NJ</td>\n",
       "      <td>Georgia sinkhole closes road swallows whole po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>55</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>World Wide!!</td>\n",
       "      <td>INEC Office in Abia Set Ablaze - http://t.co/3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>3044</td>\n",
       "      <td>death</td>\n",
       "      <td>Carry On Jutta!!!</td>\n",
       "      <td>Afghan peace talks in doubt after Mullah Omar'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>5589</td>\n",
       "      <td>flood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Internet basics: the flood defective intertiss...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>770</td>\n",
       "      <td>avalanche</td>\n",
       "      <td>South Central Wales</td>\n",
       "      <td>I saw two great punk bands making original mus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4186</th>\n",
       "      <td>5947</td>\n",
       "      <td>hazard</td>\n",
       "      <td>a van down by the river</td>\n",
       "      <td>@phiddleface NOT IF THERES A CHOKING HAZARD!!!...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>180</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>304</td>\n",
       "      <td>Sometimes you face difficulties not because yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>457</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>Canada</td>\n",
       "      <td>@ENews Ben Affleck......I know there's a wife/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>4860</td>\n",
       "      <td>evacuation</td>\n",
       "      <td>Moncton, New Brunswick</td>\n",
       "      <td>Gas leak forces evacuation in east Saint John ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>8815</td>\n",
       "      <td>sirens</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Marketforce Perth named winner of Sirens round...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>158</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>Instagram - @heyimginog</td>\n",
       "      <td>@afterShock_DeLo im speaking from someone that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>8119</td>\n",
       "      <td>rescued</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@BrittanyPetko breaking news tonight kids were...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6866</th>\n",
       "      <td>9838</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Nashville, TN</td>\n",
       "      <td>Esteemed journalist recalls tragic effects of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6860</th>\n",
       "      <td>9832</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Little Rock, AR</td>\n",
       "      <td>@thetimepast @saalon I have childhood trauma m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6231</th>\n",
       "      <td>8896</td>\n",
       "      <td>snowstorm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi yall this poem is called is the one about t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword                  location  \\\n",
       "74     107     accident            North Carolina   \n",
       "5387  7687        panic                   Toronto   \n",
       "4259  6051  heat%20wave   Arnhem, the Netherlands   \n",
       "2119  3045        death       Home of the Takers.   \n",
       "6078  8684     sinkhole           Haddonfield, NJ   \n",
       "37      55       ablaze              World Wide!!   \n",
       "2118  3044        death         Carry On Jutta!!!   \n",
       "3931  5589        flood                       NaN   \n",
       "530    770    avalanche       South Central Wales   \n",
       "4186  5947       hazard   a van down by the river   \n",
       "125    180   aftershock                       304   \n",
       "314    457   armageddon                    Canada   \n",
       "3396  4860   evacuation    Moncton, New Brunswick   \n",
       "6179  8815       sirens                    Sydney   \n",
       "108    158   aftershock  Instagram - @heyimginog    \n",
       "4        7          NaN                       NaN   \n",
       "5689  8119      rescued                       NaN   \n",
       "6866  9838       trauma             Nashville, TN   \n",
       "6860  9832       trauma           Little Rock, AR   \n",
       "6231  8896    snowstorm                       NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "74    I-77 Mile Marker 31 South Mooresville  Iredell...       1  \n",
       "5387  tomorrow's going to be a year since I went to ...       1  \n",
       "4259  Arnhem Weather - &lt;p&gt;An unrelenting and d...       1  \n",
       "2119       Y'all PUSSSSSSSSSY AND SHOOOK TO DEATH OF ME       0  \n",
       "6078  Georgia sinkhole closes road swallows whole po...       1  \n",
       "37    INEC Office in Abia Set Ablaze - http://t.co/3...       1  \n",
       "2118  Afghan peace talks in doubt after Mullah Omar'...       0  \n",
       "3931  Internet basics: the flood defective intertiss...       1  \n",
       "530   I saw two great punk bands making original mus...       0  \n",
       "4186  @phiddleface NOT IF THERES A CHOKING HAZARD!!!...       0  \n",
       "125   Sometimes you face difficulties not because yo...       0  \n",
       "314   @ENews Ben Affleck......I know there's a wife/...       0  \n",
       "3396  Gas leak forces evacuation in east Saint John ...       1  \n",
       "6179  Marketforce Perth named winner of Sirens round...       0  \n",
       "108   @afterShock_DeLo im speaking from someone that...       0  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "5689  @BrittanyPetko breaking news tonight kids were...       1  \n",
       "6866  Esteemed journalist recalls tragic effects of ...       1  \n",
       "6860  @thetimepast @saalon I have childhood trauma m...       0  \n",
       "6231  Hi yall this poem is called is the one about t...       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_shuffle=train_df.sample(frac=1,random_state=49) \n",
    "train_shuffle.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples: 7613\n",
      "Total test samples: 3263\n",
      "Total  samples: 10876\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total train samples: {len(train_df)}\")\n",
    "print(f\"Total test samples: {len(test_df)}\")\n",
    "print(f\"Total  samples: {len(train_df)+len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas(Index=3657, text='.@KurtSchlichter Yep considering that *millions* of Japanese fatalities were projected for Downfall. @_FreeMarketeer @dibang', target=1)\n",
      "Pandas(Index=1494, text='Human history becomes more and more a race between education and catastrophe.', target=0)\n",
      "Pandas(Index=1275, text='I spent 17 minutes walking with RunKeeper. 90 calories burned. #LoseIt', target=0)\n",
      "Pandas(Index=3771, text='When your heart is bigger than the obstacles  in front of you #euro #dontexpectnothing #july #fire @euro', target=0)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_index=random.randint(0, len(train_df)-4)\n",
    "\n",
    "for row in train_shuffle[['text','target']][random_index:random_index+4].itertuples():\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, test_sentences, train_labels,test_labels = train_test_split(\n",
    "    train_shuffle['text'].to_numpy(),\n",
    "    train_shuffle['target'].to_numpy(),\n",
    "    test_size=0.1, \n",
    "    random_state=49\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('O'), dtype('int64'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences.dtype, train_labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 762)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = TextVectorization(max_tokens=10000, \n",
    "                                    standardize=\"lower_and_strip_punctuation\", \n",
    "                                    output_sequence_length=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[  8, 107,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentense=\"I Love Tensorflow\"\n",
    "\n",
    "text_vectorizer([sample_sentense])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text_vectorizer.get_vocabulary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(\n",
    "                        input_dim=10000, \n",
    "                        output_dim=128, \n",
    "                        input_length=15, \n",
    "                        name = 'embeding_1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x1c8c60ad888>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(15, 128), dtype=float32, numpy=\n",
       "array([[-0.03613827, -0.01618369, -0.03479994, ...,  0.04567775,\n",
       "         0.03067318, -0.02683821],\n",
       "       [-0.02660451, -0.02514904, -0.03756065, ...,  0.00311034,\n",
       "        -0.03542763,  0.00444805],\n",
       "       [ 0.03105544, -0.02838855,  0.01726771, ...,  0.04103993,\n",
       "        -0.02632862,  0.0364282 ],\n",
       "       ...,\n",
       "       [-0.0321027 ,  0.04522001, -0.00532261, ...,  0.01040272,\n",
       "        -0.00820903,  0.03063505],\n",
       "       [-0.0321027 ,  0.04522001, -0.00532261, ...,  0.01040272,\n",
       "        -0.00820903,  0.03063505],\n",
       "       [-0.0321027 ,  0.04522001, -0.00532261, ...,  0.01040272,\n",
       "        -0.00820903,  0.03063505]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embed = embedding(text_vectorizer(\"I Love Tensorflow\"))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finish previous lection\n",
    "\n",
    "------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lection 3 start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38068\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0= Pipeline([ \n",
    "    (\"tfidf\",TfidfVectorizer()), \n",
    "    (\"clf\", MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.fit(train_sentences,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8097112860892388"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_score= model_0.score(test_sentences,test_labels)\n",
    "\n",
    "baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat0=model_0.predict(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int64),\n",
       " array([1, 0, 0, 0, 0, 0, 0, 1, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[:10], y_hat0[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "  -----\n",
    "  y_true = true labels in the form of a 1D array\n",
    "  y_pred = predicted labels in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 80.97112860892388,\n",
       " 'precision': 0.8184785838596061,\n",
       " 'recall': 0.8097112860892388,\n",
       " 'f1': 0.8032877870568117}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(test_labels,y_hat0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs,outputs,name=\"model_1_dense\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embeding_1 (Embedding)       (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "model_1_history = model_1.fit(train_sentences, train_labels, \n",
    "                                epochs=5, \n",
    "                                validation_data=(test_sentences,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.8005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44202250242233276, 0.8005249500274658]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(test_sentences,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model_1=pd.DataFrame(model_1_history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_model_1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(762,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat1=model_1.predict(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat1=tf.squeeze(tf.round(y_hat1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 80.0524934383202,\n",
       " 'precision': 0.7999739599109424,\n",
       " 'recall': 0.800524934383202,\n",
       " 'f1': 0.798159005030915}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(test_labels,y_hat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 80.97112860892388,\n",
       " 'precision': 0.8184785838596061,\n",
       " 'recall': 0.8097112860892388,\n",
       " 'f1': 0.8032877870568117}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(test_labels,y_hat0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finish previous lection\n",
    "\n",
    "------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lection 4 start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "print(x.shape)\n",
    "x = layers.LSTM(64)(x)\n",
    "print(x.shape)\n",
    "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "model_2 = tf.keras.Model(inputs,outputs,name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embeding_1 (Embedding)       (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 23ms/step - loss: 0.2169 - accuracy: 0.9235 - val_loss: 0.4856 - val_accuracy: 0.7940\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.1568 - accuracy: 0.9412 - val_loss: 0.5610 - val_accuracy: 0.7979\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 21ms/step - loss: 0.1292 - accuracy: 0.9536 - val_loss: 0.6367 - val_accuracy: 0.7835\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.1040 - accuracy: 0.9612 - val_loss: 0.6737 - val_accuracy: 0.7795\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0869 - accuracy: 0.9672 - val_loss: 0.9139 - val_accuracy: 0.7848\n"
     ]
    }
   ],
   "source": [
    "model_2_history = model_2.fit(\n",
    "                                train_sentences,train_labels, \n",
    "                                epochs=5, \n",
    "                                validation_data=(test_sentences,test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step - loss: 0.9139 - accuracy: 0.7848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9139397144317627, 0.7847769260406494]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(test_sentences,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99488473e-01],\n",
       "       [7.33628869e-01],\n",
       "       [2.47538090e-04],\n",
       "       [1.20073825e-01],\n",
       "       [4.95989949e-01],\n",
       "       [3.66065800e-02],\n",
       "       [1.29909247e-01],\n",
       "       [2.45226622e-02],\n",
       "       [7.70822763e-02],\n",
       "       [9.99882340e-01]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2=model_2.predict(test_sentences)\n",
    "\n",
    "y_hat2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
       "array([1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2=tf.squeeze(tf.round(y_hat2))\n",
    "\n",
    "y_hat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 78.4776902887139,\n",
       "  'precision': 0.7845038045965815,\n",
       "  'recall': 0.7847769028871391,\n",
       "  'f1': 0.7813428932137427},\n",
       " {'accuracy': 80.0524934383202,\n",
       "  'precision': 0.7999739599109424,\n",
       "  'recall': 0.800524934383202,\n",
       "  'f1': 0.798159005030915},\n",
       " {'accuracy': 80.97112860892388,\n",
       "  'precision': 0.8184785838596061,\n",
       "  'recall': 0.8097112860892388,\n",
       "  'f1': 0.8032877870568117})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(test_labels,y_hat2),calculate_results(test_labels,y_hat1),calculate_results(test_labels,y_hat0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "print(x.shape)\n",
    "x = layers.GRU(64)(x)\n",
    "print(x.shape)\n",
    "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "model_3 = tf.keras.Model(inputs,outputs,name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embeding_1 (Embedding)       (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 9s 28ms/step - loss: 0.1651 - accuracy: 0.9339 - val_loss: 0.7048 - val_accuracy: 0.7756\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0863 - accuracy: 0.9692 - val_loss: 0.7420 - val_accuracy: 0.7808\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0739 - accuracy: 0.9723 - val_loss: 0.8792 - val_accuracy: 0.7336\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.0641 - accuracy: 0.9747 - val_loss: 0.9204 - val_accuracy: 0.7520\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.0567 - accuracy: 0.9745 - val_loss: 1.1802 - val_accuracy: 0.7533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27a830b7c88>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(train_sentences,train_labels, \n",
    "            epochs=5, \n",
    "            validation_data=(test_sentences,test_labels)           \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 1.1802 - accuracy: 0.7533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1801807880401611, 0.7532808184623718]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(test_sentences,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9975485e-01],\n",
       "       [9.9607480e-01],\n",
       "       [3.3240176e-05],\n",
       "       [6.4064562e-03],\n",
       "       [9.9050605e-01],\n",
       "       [9.6799171e-01],\n",
       "       [2.0198077e-02],\n",
       "       [7.6154691e-01],\n",
       "       [9.1776264e-01],\n",
       "       [9.9985659e-01]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat3 = model_3.predict(test_sentences)\n",
    "\n",
    "y_hat3[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
       "array([1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat3=tf.squeeze(tf.round(y_hat3))\n",
    "\n",
    "y_hat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.32808398950131,\n",
       " 'precision': 0.7528378749972839,\n",
       " 'recall': 0.7532808398950132,\n",
       " 'f1': 0.7530383381564483}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(test_labels,y_hat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 32)\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "print(x.shape)\n",
    "x = layers.Bidirectional(layers.LSTM(16))(x)\n",
    "print(x.shape)\n",
    "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "model_4 = tf.keras.Model(inputs,outputs,name=\"model_4_Bidirectional_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_Bidirectional_LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embeding_1 (Embedding)       (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 32)                18560     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,298,593\n",
      "Trainable params: 1,298,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 9s 26ms/step - loss: 0.1712 - accuracy: 0.9572 - val_loss: 0.7754 - val_accuracy: 0.7677\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.0634 - accuracy: 0.9775 - val_loss: 0.8955 - val_accuracy: 0.7520\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.0479 - accuracy: 0.9801 - val_loss: 1.0458 - val_accuracy: 0.7533\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.0423 - accuracy: 0.9813 - val_loss: 1.1464 - val_accuracy: 0.7559\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.0398 - accuracy: 0.9813 - val_loss: 1.1761 - val_accuracy: 0.7690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27a89d86fc8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.fit(train_sentences,train_labels,epochs=5, \n",
    "validation_data=(test_sentences,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 1.1761 - accuracy: 0.7690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.176146149635315, 0.7690288424491882]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.evaluate(test_sentences,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat4 = model_4.predict(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 0., 0., 1., 0., 0., 0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat4=tf.squeeze(tf.round(y_hat4))\n",
    "\n",
    "y_hat4[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.9028871391076,\n",
       " 'precision': 0.7677129513222611,\n",
       " 'recall': 0.7690288713910761,\n",
       " 'f1': 0.7659227444514014}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(test_labels,y_hat4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finish previous lection\n",
    "\n",
    "------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lection 5 start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(49)\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5embedding = layers.Embedding(input_dim=10000, \n",
    "                                    output_dim=128, \n",
    "                                    embeddings_initializer=\"uniform\", \n",
    "                                    input_length=15, \n",
    "                                    name=\"embedding_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x= model_5embedding(x)\n",
    "x= layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x= layers.GlobalMaxPool1D()(x)\n",
    "\n",
    "outputs=layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "model_5 = tf.keras.Model(inputs,outputs, name=\"model_5_Conv1D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.compile(\n",
    "            loss=\"binary_crossentropy\", \n",
    "            optimizer=tf.keras.optimizers.Adam(), \n",
    "            metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_Conv1D\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 11, 32)            20512     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,300,545\n",
      "Trainable params: 1,300,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 25ms/step - loss: 0.5600 - accuracy: 0.7148 - val_loss: 0.4398 - val_accuracy: 0.7966\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.3378 - accuracy: 0.8603 - val_loss: 0.4326 - val_accuracy: 0.7927\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 8s 38ms/step - loss: 0.2068 - accuracy: 0.9254 - val_loss: 0.4890 - val_accuracy: 0.7900\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 10s 45ms/step - loss: 0.1323 - accuracy: 0.9571 - val_loss: 0.5438 - val_accuracy: 0.7848\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 10s 45ms/step - loss: 0.0914 - accuracy: 0.9705 - val_loss: 0.5895 - val_accuracy: 0.7795\n"
     ]
    }
   ],
   "source": [
    "model_5_history= model_5.fit(\n",
    "    train_sentences,train_labels, epochs=5, validation_data=(test_sentences, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat5=model_5.predict(test_sentences)\n",
    "\n",
    "y_hat5[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 0., 0., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat5=tf.squeeze(tf.round(y_hat5))\n",
    "\n",
    "y_hat5[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.95275590551181,\n",
       " 'precision': 0.7783357964309078,\n",
       " 'recall': 0.7795275590551181,\n",
       " 'f1': 0.7785795351432463}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(y_true=test_labels, y_pred=y_hat5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'AutoTrackable' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1920/2752408442.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0membed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://tfhub.dev/google/universal-sentence-encoder-lite/2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"I love tensorflow\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'AutoTrackable' object is not callable"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-lite/2\")\n",
    "\n",
    "es=embed([\"I love tensorflow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-lite/2\") # load Universal Sentence Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'es' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1920/3820788746.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'es' is not defined"
     ]
    }
   ],
   "source": [
    "es=embed(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    C:\\Users\\38068\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:229 call  *\n        result = f()\n    C:\\Users\\38068\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1707 __call__  **\n        return self._call_impl(args, kwargs)\n    C:\\Users\\38068\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py:247 _call_impl\n        args, kwargs, cancellation_manager)\n    C:\\Users\\38068\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1725 _call_impl\n        return self._call_with_flat_signature(args, kwargs, cancellation_manager)\n    C:\\Users\\38068\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1747 _call_with_flat_signature\n        len(args)))\n\n    TypeError: pruned(dense_shape, values, indices) takes 0 positional arguments but 1 were given\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1920/3466219620.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"string\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentence_encoder_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sigmoid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m--> 977\u001b[1;33m                                                 input_list)\n\u001b[0m\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m     \u001b[1;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1113\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[1;32m-> 1115\u001b[1;33m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[0;32m   1116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    846\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    886\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    C:\\Users\\38068\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:229 call  *\n        result = f()\n    C:\\Users\\38068\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1707 __call__  **\n        return self._call_impl(args, kwargs)\n    C:\\Users\\38068\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py:247 _call_impl\n        args, kwargs, cancellation_manager)\n    C:\\Users\\38068\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1725 _call_impl\n        return self._call_with_flat_signature(args, kwargs, cancellation_manager)\n    C:\\Users\\38068\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1747 _call_with_flat_signature\n        len(args)))\n\n    TypeError: pruned(dense_shape, values, indices) takes 0 positional arguments but 1 were given\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
    "x = sentence_encoder_layer(inputs)\n",
    "x= layers.Dense(64,activation=\"relu\")(x)\n",
    "outputs=layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "model_6 = tf.keras.Model(inputs,outputs, name=\"model_6_USE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6_history=model_6.fit(train_sentences,train_labels,epochs=5,\n",
    "                        validation_data=(test_sentences,train_labels))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45c35a36beb3d1c2f42a56be9142246513f9d24015e8e4e22f7c95d5b06ff02e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('tutorialspoint': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
