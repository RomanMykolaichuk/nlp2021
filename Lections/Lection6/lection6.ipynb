{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('../Lection5/nlp_start/train.csv')\n",
    "test_df=pd.read_csv('../Lection5/nlp_start/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>107</td>\n",
       "      <td>accident</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>I-77 Mile Marker 31 South Mooresville  Iredell...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>7687</td>\n",
       "      <td>panic</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>tomorrow's going to be a year since I went to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4259</th>\n",
       "      <td>6051</td>\n",
       "      <td>heat%20wave</td>\n",
       "      <td>Arnhem, the Netherlands</td>\n",
       "      <td>Arnhem Weather - &amp;lt;p&amp;gt;An unrelenting and d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>3045</td>\n",
       "      <td>death</td>\n",
       "      <td>Home of the Takers.</td>\n",
       "      <td>Y'all PUSSSSSSSSSY AND SHOOOK TO DEATH OF ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>8684</td>\n",
       "      <td>sinkhole</td>\n",
       "      <td>Haddonfield, NJ</td>\n",
       "      <td>Georgia sinkhole closes road swallows whole po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>55</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>World Wide!!</td>\n",
       "      <td>INEC Office in Abia Set Ablaze - http://t.co/3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>3044</td>\n",
       "      <td>death</td>\n",
       "      <td>Carry On Jutta!!!</td>\n",
       "      <td>Afghan peace talks in doubt after Mullah Omar'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>5589</td>\n",
       "      <td>flood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Internet basics: the flood defective intertiss...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>770</td>\n",
       "      <td>avalanche</td>\n",
       "      <td>South Central Wales</td>\n",
       "      <td>I saw two great punk bands making original mus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4186</th>\n",
       "      <td>5947</td>\n",
       "      <td>hazard</td>\n",
       "      <td>a van down by the river</td>\n",
       "      <td>@phiddleface NOT IF THERES A CHOKING HAZARD!!!...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>180</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>304</td>\n",
       "      <td>Sometimes you face difficulties not because yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>457</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>Canada</td>\n",
       "      <td>@ENews Ben Affleck......I know there's a wife/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>4860</td>\n",
       "      <td>evacuation</td>\n",
       "      <td>Moncton, New Brunswick</td>\n",
       "      <td>Gas leak forces evacuation in east Saint John ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>8815</td>\n",
       "      <td>sirens</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Marketforce Perth named winner of Sirens round...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>158</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>Instagram - @heyimginog</td>\n",
       "      <td>@afterShock_DeLo im speaking from someone that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>8119</td>\n",
       "      <td>rescued</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@BrittanyPetko breaking news tonight kids were...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6866</th>\n",
       "      <td>9838</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Nashville, TN</td>\n",
       "      <td>Esteemed journalist recalls tragic effects of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6860</th>\n",
       "      <td>9832</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Little Rock, AR</td>\n",
       "      <td>@thetimepast @saalon I have childhood trauma m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6231</th>\n",
       "      <td>8896</td>\n",
       "      <td>snowstorm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi yall this poem is called is the one about t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword                  location  \\\n",
       "74     107     accident            North Carolina   \n",
       "5387  7687        panic                   Toronto   \n",
       "4259  6051  heat%20wave   Arnhem, the Netherlands   \n",
       "2119  3045        death       Home of the Takers.   \n",
       "6078  8684     sinkhole           Haddonfield, NJ   \n",
       "37      55       ablaze              World Wide!!   \n",
       "2118  3044        death         Carry On Jutta!!!   \n",
       "3931  5589        flood                       NaN   \n",
       "530    770    avalanche       South Central Wales   \n",
       "4186  5947       hazard   a van down by the river   \n",
       "125    180   aftershock                       304   \n",
       "314    457   armageddon                    Canada   \n",
       "3396  4860   evacuation    Moncton, New Brunswick   \n",
       "6179  8815       sirens                    Sydney   \n",
       "108    158   aftershock  Instagram - @heyimginog    \n",
       "4        7          NaN                       NaN   \n",
       "5689  8119      rescued                       NaN   \n",
       "6866  9838       trauma             Nashville, TN   \n",
       "6860  9832       trauma           Little Rock, AR   \n",
       "6231  8896    snowstorm                       NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "74    I-77 Mile Marker 31 South Mooresville  Iredell...       1  \n",
       "5387  tomorrow's going to be a year since I went to ...       1  \n",
       "4259  Arnhem Weather - &lt;p&gt;An unrelenting and d...       1  \n",
       "2119       Y'all PUSSSSSSSSSY AND SHOOOK TO DEATH OF ME       0  \n",
       "6078  Georgia sinkhole closes road swallows whole po...       1  \n",
       "37    INEC Office in Abia Set Ablaze - http://t.co/3...       1  \n",
       "2118  Afghan peace talks in doubt after Mullah Omar'...       0  \n",
       "3931  Internet basics: the flood defective intertiss...       1  \n",
       "530   I saw two great punk bands making original mus...       0  \n",
       "4186  @phiddleface NOT IF THERES A CHOKING HAZARD!!!...       0  \n",
       "125   Sometimes you face difficulties not because yo...       0  \n",
       "314   @ENews Ben Affleck......I know there's a wife/...       0  \n",
       "3396  Gas leak forces evacuation in east Saint John ...       1  \n",
       "6179  Marketforce Perth named winner of Sirens round...       0  \n",
       "108   @afterShock_DeLo im speaking from someone that...       0  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "5689  @BrittanyPetko breaking news tonight kids were...       1  \n",
       "6866  Esteemed journalist recalls tragic effects of ...       1  \n",
       "6860  @thetimepast @saalon I have childhood trauma m...       0  \n",
       "6231  Hi yall this poem is called is the one about t...       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_shuffle=train_df.sample(frac=1,random_state=49) \n",
    "train_shuffle.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples: 7613\n",
      "Total test samples: 3263\n",
      "Total  samples: 10876\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total train samples: {len(train_df)}\")\n",
    "print(f\"Total test samples: {len(test_df)}\")\n",
    "print(f\"Total  samples: {len(train_df)+len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas(Index=420, text='Bloor/Ossington arsonist also burned a mattress on Northumberland St #cbcto http://t.co/wpDvT31sne', target=0)\n",
      "Pandas(Index=2620, text='@LT3dave so many specs so much fan service so much lore destruction', target=0)\n",
      "Pandas(Index=4872, text='Not only are you a mass murderer but at a movie theatre where niggas dropped bread to see a movie? Cmon man.', target=0)\n",
      "Pandas(Index=2390, text='Dozens dead as two trains derail over river in India http://t.co/zkKn6mSE1n http://t.co/FzHJF8BXlD', target=1)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_index=random.randint(0, len(train_df)-4)\n",
    "\n",
    "for row in train_shuffle[['text','target']][random_index:random_index+4].itertuples():\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, test_sentences, train_labels,test_labels = train_test_split(\n",
    "    train_shuffle['text'].to_numpy(),\n",
    "    train_shuffle['target'].to_numpy(),\n",
    "    test_size=0.1, \n",
    "    random_state=49\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('O'), dtype('int64'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences.dtype, train_labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 762)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = TextVectorization(max_tokens=10000, \n",
    "                                    standardize=\"lower_and_strip_punctuation\", \n",
    "                                    output_sequence_length=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[  8, 107,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentense=\"I Love Tensorflow\"\n",
    "\n",
    "text_vectorizer([sample_sentense])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text_vectorizer.get_vocabulary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(\n",
    "                        input_dim=10000, \n",
    "                        output_dim=128, \n",
    "                        input_length=15, \n",
    "                        name = 'embeding_1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x2145248e6c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(15, 128), dtype=float32, numpy=\n",
       "array([[-0.00399926,  0.0213283 ,  0.04242614, ...,  0.02847807,\n",
       "        -0.02096679,  0.00185518],\n",
       "       [ 0.02454695,  0.03934847, -0.00569483, ...,  0.02452961,\n",
       "         0.04083823, -0.00445603],\n",
       "       [-0.0222628 ,  0.00700254,  0.01960233, ..., -0.04525923,\n",
       "         0.00744903, -0.04620118],\n",
       "       ...,\n",
       "       [-0.04483178, -0.00381769,  0.01230688, ..., -0.0416295 ,\n",
       "         0.0351048 , -0.04566411],\n",
       "       [-0.04483178, -0.00381769,  0.01230688, ..., -0.0416295 ,\n",
       "         0.0351048 , -0.04566411],\n",
       "       [-0.04483178, -0.00381769,  0.01230688, ..., -0.0416295 ,\n",
       "         0.0351048 , -0.04566411]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embed = embedding(text_vectorizer(\"I Love Tensorflow\"))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finish previous lection\n",
    "\n",
    "------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lection 3 start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38068\\.conda\\envs\\tutorialspoint\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0= Pipeline([ \n",
    "    (\"tfidf\",TfidfVectorizer()), \n",
    "    (\"clf\", MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.fit(train_sentences,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8097112860892388"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_score= model_0.score(test_sentences,test_labels)\n",
    "\n",
    "baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat0=model_0.predict(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int64),\n",
       " array([1, 0, 0, 0, 0, 0, 0, 1, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[:10], y_hat0[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "  -----\n",
    "  y_true = true labels in the form of a 1D array\n",
    "  y_pred = predicted labels in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 80.97112860892388,\n",
       " 'precision': 0.8184785838596061,\n",
       " 'recall': 0.8097112860892388,\n",
       " 'f1': 0.8032877870568117}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(test_labels,y_hat0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs,outputs,name=\"model_1_dense\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embeding_1 (Embedding)       (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 24ms/step - loss: 0.6115 - accuracy: 0.6897 - val_loss: 0.5208 - val_accuracy: 0.7730\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 16ms/step - loss: 0.4435 - accuracy: 0.8170 - val_loss: 0.4421 - val_accuracy: 0.8071\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 16ms/step - loss: 0.3495 - accuracy: 0.8618 - val_loss: 0.4263 - val_accuracy: 0.8123\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.2862 - accuracy: 0.8905 - val_loss: 0.4317 - val_accuracy: 0.8084\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.2387 - accuracy: 0.9117 - val_loss: 0.4436 - val_accuracy: 0.8005\n"
     ]
    }
   ],
   "source": [
    "model_1_history = model_1.fit(train_sentences, train_labels, \n",
    "                                epochs=5, \n",
    "                                validation_data=(test_sentences,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.8005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44356831908226013, 0.8005249500274658]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(test_sentences,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model_1=pd.DataFrame(model_1_history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_model_1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(762,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat1=model_1.predict(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat1=tf.squeeze(tf.round(y_hat1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 80.0524934383202,\n",
       " 'precision': 0.7995638255896308,\n",
       " 'recall': 0.800524934383202,\n",
       " 'f1': 0.7987526167895771}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(test_labels,y_hat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 80.97112860892388,\n",
       " 'precision': 0.8184785838596061,\n",
       " 'recall': 0.8097112860892388,\n",
       " 'f1': 0.8032877870568117}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(test_labels,y_hat0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finish previous lection\n",
    "\n",
    "------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lection 4 start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "print(x.shape)\n",
    "x = layers.LSTM(64)(x)\n",
    "print(x.shape)\n",
    "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "model_2 = tf.keras.Model(inputs,outputs,name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embeding_1 (Embedding)       (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 8s 24ms/step - loss: 0.2277 - accuracy: 0.9165 - val_loss: 0.5040 - val_accuracy: 0.8045\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.1529 - accuracy: 0.9451 - val_loss: 0.6752 - val_accuracy: 0.7782\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 6s 27ms/step - loss: 0.1297 - accuracy: 0.9548 - val_loss: 0.5699 - val_accuracy: 0.7861\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.1070 - accuracy: 0.9610 - val_loss: 0.7227 - val_accuracy: 0.7848\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.0858 - accuracy: 0.9663 - val_loss: 0.7746 - val_accuracy: 0.7743\n"
     ]
    }
   ],
   "source": [
    "model_2_history = model_2.fit(\n",
    "                                train_sentences,train_labels, \n",
    "                                epochs=5, \n",
    "                                validation_data=(test_sentences,test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 0.7746 - accuracy: 0.7743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.774585485458374, 0.7742782235145569]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(test_sentences,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9854833e-01],\n",
       "       [8.3367795e-01],\n",
       "       [8.6164474e-04],\n",
       "       [4.0258467e-01],\n",
       "       [5.2180851e-01],\n",
       "       [3.7958914e-01],\n",
       "       [1.9576666e-01],\n",
       "       [5.9322566e-02],\n",
       "       [8.1126899e-02],\n",
       "       [9.9983454e-01]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2=model_2.predict(test_sentences)\n",
    "\n",
    "y_hat2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
       "array([1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2=tf.squeeze(tf.round(y_hat2))\n",
    "\n",
    "y_hat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 77.42782152230971,\n",
       "  'precision': 0.7727560393294721,\n",
       "  'recall': 0.7742782152230971,\n",
       "  'f1': 0.7725864527237782},\n",
       " {'accuracy': 80.0524934383202,\n",
       "  'precision': 0.7995638255896308,\n",
       "  'recall': 0.800524934383202,\n",
       "  'f1': 0.7987526167895771},\n",
       " {'accuracy': 80.97112860892388,\n",
       "  'precision': 0.8184785838596061,\n",
       "  'recall': 0.8097112860892388,\n",
       "  'f1': 0.8032877870568117})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(test_labels,y_hat2),calculate_results(test_labels,y_hat1),calculate_results(test_labels,y_hat0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "print(x.shape)\n",
    "x = layers.GRU(64)(x)\n",
    "print(x.shape)\n",
    "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "model_3 = tf.keras.Model(inputs,outputs,name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embeding_1 (Embedding)       (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 8s 26ms/step - loss: 0.1628 - accuracy: 0.9384 - val_loss: 0.7381 - val_accuracy: 0.7585\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 6s 26ms/step - loss: 0.0834 - accuracy: 0.9710 - val_loss: 0.8136 - val_accuracy: 0.7598\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0741 - accuracy: 0.9729 - val_loss: 0.8077 - val_accuracy: 0.7703\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.0627 - accuracy: 0.9747 - val_loss: 0.8547 - val_accuracy: 0.7717\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.0589 - accuracy: 0.9762 - val_loss: 1.0180 - val_accuracy: 0.7507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21459f257c8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(train_sentences,train_labels, \n",
    "            epochs=5, \n",
    "            validation_data=(test_sentences,test_labels)           \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 1.0180 - accuracy: 0.7507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0179933309555054, 0.7506561875343323]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(test_sentences,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9979544e-01],\n",
       "       [9.9464631e-01],\n",
       "       [2.0626187e-04],\n",
       "       [4.2023152e-02],\n",
       "       [9.7491050e-01],\n",
       "       [9.7601277e-01],\n",
       "       [1.9881132e-01],\n",
       "       [2.6859438e-01],\n",
       "       [9.0889609e-01],\n",
       "       [9.9989808e-01]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat3 = model_3.predict(test_sentences)\n",
    "\n",
    "y_hat3[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
       "array([1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat3=tf.squeeze(tf.round(y_hat3))\n",
    "\n",
    "y_hat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.06561679790026,\n",
       " 'precision': 0.7514286498972695,\n",
       " 'recall': 0.7506561679790026,\n",
       " 'f1': 0.7509955435558505}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(test_labels,y_hat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 32)\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "print(x.shape)\n",
    "x = layers.Bidirectional(layers.LSTM(16))(x)\n",
    "print(x.shape)\n",
    "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "model_4 = tf.keras.Model(inputs,outputs,name=\"model_4_Bidirectional_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_Bidirectional_LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embeding_1 (Embedding)       (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 32)                18560     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,298,593\n",
      "Trainable params: 1,298,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 8s 22ms/step - loss: 0.1670 - accuracy: 0.9613 - val_loss: 0.7397 - val_accuracy: 0.7651\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.0671 - accuracy: 0.9762 - val_loss: 0.8940 - val_accuracy: 0.7441\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.0544 - accuracy: 0.9762 - val_loss: 0.9846 - val_accuracy: 0.7690\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0460 - accuracy: 0.9807 - val_loss: 1.0298 - val_accuracy: 0.7520\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.0417 - accuracy: 0.9791 - val_loss: 1.2122 - val_accuracy: 0.7454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2145e18ee88>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.fit(train_sentences,train_labels,epochs=5, \n",
    "validation_data=(test_sentences,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 1.2122 - accuracy: 0.7454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2122479677200317, 0.7454068064689636]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.evaluate(test_sentences,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat4 = model_4.predict(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 0., 0., 1., 1., 0., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat4=tf.squeeze(tf.round(y_hat4))\n",
    "\n",
    "y_hat4[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 74.54068241469817,\n",
       " 'precision': 0.7436407903224552,\n",
       " 'recall': 0.7454068241469817,\n",
       " 'f1': 0.7439988378693527}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(test_labels,y_hat4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finish previous lection\n",
    "\n",
    "------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lection 5 start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(49)\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5embedding = layers.Embedding(input_dim=10000, \n",
    "                                    output_dim=128, \n",
    "                                    embeddings_initializer=\"uniform\", \n",
    "                                    input_length=15, \n",
    "                                    name=\"embedding_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x= model_5embedding(x)\n",
    "x= layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x= layers.GlobalMaxPool1D()(x)\n",
    "\n",
    "outputs=layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "model_5 = tf.keras.Model(inputs,outputs, name=\"model_5_Conv1D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.compile(\n",
    "            loss=\"binary_crossentropy\", \n",
    "            optimizer=tf.keras.optimizers.Adam(), \n",
    "            metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_Conv1D\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 11, 32)            20512     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,300,545\n",
      "Trainable params: 1,300,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 25ms/step - loss: 0.5629 - accuracy: 0.7190 - val_loss: 0.4354 - val_accuracy: 0.8058\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 6s 26ms/step - loss: 0.3407 - accuracy: 0.8578 - val_loss: 0.4342 - val_accuracy: 0.8058\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.2103 - accuracy: 0.9223 - val_loss: 0.4987 - val_accuracy: 0.7913\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.1339 - accuracy: 0.9581 - val_loss: 0.5580 - val_accuracy: 0.7927\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0941 - accuracy: 0.9701 - val_loss: 0.5974 - val_accuracy: 0.7887\n"
     ]
    }
   ],
   "source": [
    "model_5_history= model_5.fit(\n",
    "    train_sentences,train_labels, epochs=5, validation_data=(test_sentences, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9873441 ],\n",
       "       [0.30326307],\n",
       "       [0.29388368],\n",
       "       [0.82518697],\n",
       "       [0.81672925],\n",
       "       [0.01382145],\n",
       "       [0.05414483],\n",
       "       [0.10373542],\n",
       "       [0.7643857 ],\n",
       "       [0.99999744]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat5=model_5.predict(test_sentences)\n",
    "\n",
    "y_hat5[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 0., 0., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat5=tf.squeeze(tf.round(y_hat5))\n",
    "\n",
    "y_hat5[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.87139107611549,\n",
       " 'precision': 0.7874771155108337,\n",
       " 'recall': 0.7887139107611548,\n",
       " 'f1': 0.7874783506734244}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(y_true=test_labels, y_pred=y_hat5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "url=\"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "\n",
    "sentence_encoder_layer = hub.KerasLayer(url,input_shape=[], # shape of inputs coming to our model \n",
    "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
    "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
    "                                        name=\"USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "USE (KerasLayer)             (None, 512)               256797824 \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model using the Sequential API\n",
    "model_6 = tf.keras.Sequential([\n",
    "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
    "  layers.Dense(64, activation=\"relu\"),\n",
    "  layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_6_USE\")\n",
    "\n",
    "# Compile model\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 10ms/step - loss: 0.5096 - accuracy: 0.7822 - val_loss: 0.4186 - val_accuracy: 0.8084\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.4191 - accuracy: 0.8145 - val_loss: 0.4022 - val_accuracy: 0.8110\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.4045 - accuracy: 0.8234 - val_loss: 0.3972 - val_accuracy: 0.8189\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.3959 - accuracy: 0.8243 - val_loss: 0.3987 - val_accuracy: 0.8202\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.3874 - accuracy: 0.8313 - val_loss: 0.3972 - val_accuracy: 0.8150\n"
     ]
    }
   ],
   "source": [
    "model_6_history=model_6.fit(train_sentences,train_labels,epochs=5,\n",
    "                        validation_data=(test_sentences,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8960887 ],\n",
       "       [0.15786627],\n",
       "       [0.10572582],\n",
       "       [0.37096328],\n",
       "       [0.07094651],\n",
       "       [0.10888442],\n",
       "       [0.31734583],\n",
       "       [0.10547283],\n",
       "       [0.52195483],\n",
       "       [0.97183394]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat6=model_6.predict(test_sentences)\n",
    "\n",
    "y_hat6[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat6=tf.squeeze(tf.round(y_hat6))\n",
    "\n",
    "y_hat6[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.49606299212599,\n",
       " 'precision': 0.8140768036413563,\n",
       " 'recall': 0.8149606299212598,\n",
       " 'f1': 0.8138785555587134}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(test_labels,y_hat6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finish previous lection\n",
    "\n",
    "------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lection 6 start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_hub_embedding_layer = hub.KerasLayer(url,input_shape=[], # shape of inputs coming to our model \n",
    "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
    "                                        trainable=True, \n",
    "                                        name=\"USE-FT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7_USE_fine_tuning\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "USE-FT (KerasLayer)          (None, 512)               256797824 \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 256,830,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_7 = tf.keras.Sequential([\n",
    "  tf_hub_embedding_layer, # take in sentences and then encode them into an embedding\n",
    "  layers.Dense(64, activation=\"relu\"),\n",
    "  layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_7_USE_fine_tuning\")\n",
    "\n",
    "# Compile model\n",
    "model_7.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7_history=model_7.fit(train_sentences,train_labels,epochs=2,\n",
    "                        validation_data=(test_sentences,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 82.1522309711286,\n",
       " 'precision': 0.8297666330569283,\n",
       " 'recall': 0.821522309711286,\n",
       " 'f1': 0.8160130562361804}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat7=model_7.predict(test_sentences)\n",
    "y_hat7=tf.squeeze(tf.round(y_hat7))\n",
    "calculate_results(test_labels,y_hat7)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45c35a36beb3d1c2f42a56be9142246513f9d24015e8e4e22f7c95d5b06ff02e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('tutorialspoint': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
